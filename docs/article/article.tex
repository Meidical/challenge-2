\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{microtype}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{url}
\usepackage{placeins}
\usepackage{tabularx}
\usepackage[hidelinks]{hyperref}
\usepackage{dblfloatfix}
\usepackage{booktabs}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\begin{document}

\title{Donor-Recipient Matching and Allocation
    in Pediatric Bone-Marrow Transplantation\\}

\author{
    \fontsize{10pt}{11pt}\selectfont
    \begin{tabular}{ccc}
        \begin{tabular}{c}
            Danilo Silva                                   \\
            \textit{Department of Artificial Intelligence} \\
            \textit{Polytechnic School of Porto}           \\
            Porto, Portugal                                \\
            1250424@isep.ipp.pt
        \end{tabular}
         &
        \begin{tabular}{c}
            Luís Magalhães                                 \\
            \textit{Department of Artificial Intelligence} \\
            \textit{Polytechnic School of Porto}           \\
            Porto, Portugal                                \\
            1100628@isep.ipp.pt
        \end{tabular}
         &
        \begin{tabular}{c}
            José Domingues                                 \\
            \textit{Department of Artificial Intelligence} \\
            \textit{Polytechnic School of Porto}           \\
            Porto, Portugal                                \\
            1000984@isep.ipp.pt
        \end{tabular}
        \\[6ex]
        \begin{tabular}{c}
            Ricardo Sousa                                  \\
            \textit{Department of Artificial Intelligence} \\
            \textit{Polytechnic School of Porto}           \\
            Porto, Portugal                                \\
            1201856@isep.ipp.pt
        \end{tabular}
         &
        \begin{tabular}{c}
            Tomás Pereira                                  \\
            \textit{Department of Artificial Intelligence} \\
            \textit{Polytechnic School of Porto}           \\
            Porto, Portugal                                \\
            1210830@isep.ipp.pt
        \end{tabular}
    \end{tabular}
}

\maketitle

\begin{abstract}
Pediatric allogeneic hematopoietic stem cell transplantation (HSCT) is a potentially curative therapy for malignant and non-malignant diseases, but outcomes depend strongly on donor-recipient compatibility and graft characteristics. Donor selection is therefore a high-stakes, time-sensitive decision in which clinicians must balance immunogenetic risk against urgency and donor availability.
This work proposes a decision-support system integrated with predictive artificial intelligence models. The multi-criteria decision-making method TOPSIS (Technique for Order Preference by Similarity to Ideal Solution) is employed to rank and select the most suitable donor for a given recipient. One of the decision criteria is the predicted post-transplant survival time of the recipient (benefit criterion), which is estimated using a machine learning model trained on a published pediatric unrelated-donor cohort.
The overall goal is to support transparent, reproducible, and clinically meaningful donor-recipient matching and allocation decisions in pediatric HSCT.
Experimental results demonstrate that an XGBoost (eXtreme Gradient Boosting) model with the help of Generative Adversarial Networks (GANs) achieved the best predictive performance for post-transplant probability of survival, reaching an F1-Score of 0.65. This probability was then used to predict the expected post-transplant survival time in case of death. For this regression task, the best performing model was an Extra Trees Regressor model, which achieved a Root Mean Square Error (RMSE) of 560, significantly outperforming baseline level (913 RMSE).

\end{abstract}


\begin{IEEEkeywords}
    Pediatric hematopoietic stem cell transplantation,
    donor-recipient matching, machine learning, data-driven decision support, multi-criteria decision making
\end{IEEEkeywords}


\section{Introduction}
Allogeneic hematopoietic stem cell transplantation (HSCT) is an established therapeutic option for a wide range of malignant and non-malignant hematologic conditions in pediatric populations and often represents the standard of care in high-risk cases; however, it carries substantial clinical risks, such as graft-versus-host disease and transplant-related mortality, which necessitate careful donor selection~\cite{Diaz2024}. 
In clinical practice, transplant success is tightly linked to donor-recipient compatibility and to graft characteristics (the material transplanted from the donor to the recipient, such as CD34$^{+}$ and CD3$^{+}$ cells), because immunologic disparity can increase complications such as graft-versus-host disease (GVHD), graft failure, and transplant-related mortality \cite{Tiercy2016}. 
Donor selection is typically guided by high-resolution Human Leukocyte Antigen (HLA) matching and additional donor/recipient factors (e.g., Cytomegalovirus (CMV) status, age, stem cell source - bone marrow or peripheral blood stem cells), while acknowledging that not all patients have access to an ideal matched sibling and that alternative donor options are frequently required \cite{Tiercy2016}. 
Beyond “match counts,” functional and locus-specific approaches, referring to specific genomic positions associated with immunogenetic variability, can refine immunological risk; for example, classification of HLA-DPB1 mismatches into permissive vs non-permissive groups has been associated with clinically relevant differences in outcomes \cite{Fleischhauer2012}. In parallel, the availability of large transplantation registries and richer clinical data has motivated machine learning (ML) approaches to outcome prediction (e.g., early mortality, GVHD risk). Prior work has shown that ML can produce clinically meaningful risk stratification, but performance and generalizability depend heavily on data preparation choices and robust validation designs \cite{Shouval2015}, \cite{Arai2019}, \cite{Tang2020}. \\

Despite established donor selection principles, there is still a lack of integrated, transparent frameworks that (i) formalize donor-recipient allocation under multiple clinical criteria and (ii) incorporate data-driven outcome predictions using only pre-decision variables. This work proposes a decision-support system integrated with predictive artificial intelligence models. Donor allocation is formulated as a multi-criteria decision-making problem, in which alternative ranking is performed using the Technique for Order Preference by Similarity to Ideal Solution (TOPSIS), with criterion weights calculated by the Analytic Hierarchy Process (AHP). Recipient post-transplant survival time is estimated by a machine learning model trained on a dataset \cite{Sikora2010} derived from a published pediatric unrelated-donor cohort \cite{Kalwak2010}. The expected survival time (serves as post-graft prognosis) is incorporated as one of the decision criteria, yielding an ordered list of candidate matches for clinical review.
When a donor is chosen, another model tries to predict the patient's relapse based on previous features and new transplant related ones, providing additional support to the clinician.

\section{State-of-the-Art}

Allogeneic hematopoietic stem cell transplantation (HSCT) stands as the unique curative option for various pediatric patients with malignant and non-malignant hematologic diseases \cite{Diaz2024}. The success of the transplant critically depends on Human Leukocyte Antigen (HLA) compatibility between the donor and recipient. Although the gold standard is a 10/10 genotypic match (HLA-A, -B, -C, -DRB1, -DQB1), approximately 70\% of patients do not have a compatible family donor, necessitating the use of unrelated or haploidentical donors \cite{Shouval2015}.

The complexity of immunogenetics, with thousands of known HLA alleles, combined with the heterogeneity of clinical data, has rendered traditional statistical approaches (such as Cox regression) insufficient for capturing complex non-linear interactions. Consequently, the application of Machine Learning (ML) algorithms has emerged as a vital tool for predicting outcomes (survival, Graft-versus-Host Disease (GVHD)) and supporting donor allocation \cite{Shouval2014}, \cite{Gupta2020}.

This section reviews the literature, focusing on data preparation and model validation methodologies.

\subsection{Data preparation and feature engineering}

The quality of ML models depends intrinsically on data preparation. The literature identifies three critical vectors in this phase:\\

\begin{enumerate}
    \item \textbf{HLA resolution and complexity: } high-resolution typing (allelic level) is fundamental. Lee et al. \cite{Lee2007} demonstrated in a landmark study that high-resolution matching at HLA-A, -B, -C, and -DRB1 is associated with higher survival rates. Simple binary categorization (matched/mismatched) is insufficient; recent models incorporate the distinction between ``permissive'' and ``non-permissive'' mismatches, particularly at the HLA-DPB1 locus, based on T-cell epitopes. Fleischhauer et al. \cite{Fleischhauer2012} validated that non-permissive mismatches significantly increase mortality, making this a crucial feature for predictive algorithms. \\

    \item \textbf{Specific clinical and pediatric variables: } beyond HLA, feature engineering must include donor and graft-specific factors. Kałwak et al. \cite{Kalwak2010}, in a study focused on pediatrics, highlighted that higher doses of CD34\textsuperscript{+} and CD3\textsuperscript{+} cells in the graft promote better long-term survival without increasing the risk of severe GVHD. The inclusion of these quantitative biological variables enriches ML models. Additionally, Tang et al. \cite{Tang2020} innovated by using longitudinal vital sign data (e.g., temperature, blood pressure) extracted from Electronic Health Records (EHR), demonstrating that temporal trends (slopes) are stronger predictors of acute GVHD than static measurements.\\

    \item \textbf{Missing data treatment and feature selection: } because real-world databases may contain noise and missing data, Shouval et al. \cite{Shouval2014} discuss the need for robust preprocessing, including imputation and discretization. Feature selection is critical to avoid hyper-dimensionality. For instance, in a data mining study involving 28,236 patients, the Alternating Decision Tree (ADTree) algorithm automatically selected 10 out of 20 possible variables, eliminating redundancies (e.g., combining donor/recipient Cytomegalovirus (CMV) serostatus into a single interaction variable) \cite{Shouval2015}.\\
\end{enumerate}


\subsection{ML models and validation strategies}

The transition from classical statistical models to ML requires rigorous validation to avoid overfitting, where the model memorizes training data but fails to generalize \cite{Shouval2014}.

\begin{enumerate}
    \item \textbf{Predictive algorithms:} recent literature favors algorithms that balance accuracy with clinical interpretability:

          \begin{itemize}
              \item \textbf{Decision trees and ensemble methods:} Shouval et al. \cite{Shouval2015} and Arai et al. \cite{Arai2019} successfully used the ADTree algorithm to predict mortality and GVHD, respectively. ADTree was preferred over Artificial Neural Networks (ANN) or Random Forests because it allows for the visualization of decision rules and interactions (e.g., the impact of disease stage varies by age), whereas ``black box'' models hide this logic.

              \item \textbf{Penalized logistic regression:} Tang et al. \cite{Tang2020} used L2 regularization to handle collinearity in longitudinal vital sign data, outperforming baseline models that used only static characteristics.\\
          \end{itemize}

    \item \textbf{Validation methodologies:} robust validation is consistent across high-quality studies:

          \begin{itemize}
              \item \textbf{Train/test split:} Arai et al.  \cite{Arai2019}. randomly divided a cohort of 26,695 patients into training (70\%) and validation (30\%) sets. The trained model was tested on the validation cohort, demonstrating clear risk stratification (hazard ratio 2.57 for high risk vs. low risk).

              \item \textbf{Cross-validation:} Both Shouval et al. \cite{Shouval2014} and Gupta et al. \cite{Gupta2020} advocate for the use of 10-fold cross-validation on the training set to optimize hyperparameters prior to final testing.

              \item \textbf{Calibration:} accuracy (AUC) is not the only metric. Shouval et al. \cite{Shouval2014} emphasize the importance of calibration (agreement between predicted and observed probability), demonstrating excellent consistency in their 100-day mortality model .\\
          \end{itemize}
\end{enumerate}

\subsection{From prediction to allocation}
While ML models provide a risk score (prediction), clinical decision-making requires selecting the best donor among several available options (allocation). The literature suggests a ``prediction-to-decision'' gap \cite{Shouval2014}. Multiple Attribute Decision Making (MADM) methodologies, such as TOPSIS (Technique for Order Preference by Similarity to Ideal Solution), described by Tzeng \& Huang \cite{Tzeng2011}, allow for the integration of ML predictions (as criteria) into an ordered ranking of alternatives.
Beyond predictive performance, the literature emphasizes the need to integrate ML models into structured clinical decision workflows to ensure transparency, traceability, and clinician oversight \cite{tun_trust_2025}. Multi-criteria decision analysis methods provide a structured and rigorous framework to combine heterogeneous clinical factors and predictive information into reproducible and auditable rankings \cite{dolan_multi-criteria_2010}. However, few studies report end-to-end architectures that integrate validated predictive models with formal decision-making pipelines in transplantation contexts \cite{preti_implementation_2024}. This gap motivates the development of the proposed integrated decision-support framework.


\section{Methodology}
The main system aims to use the transformations necessary to join, process and retain the data necessary for each stage of the alocation and estimation process. While the original dataset was used to train the models, exploratory analysis and context of the specialization, synthetic datasets were need to be created in order to be able to test and use the system in the prespective of a professional.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\columnwidth]{figures/data_flow.png}
    \caption{Data Flow Diagram}
    \label{fig:data_flow}
\end{figure}

The proposed methodology formulates pediatric bone marrow donor–recipient allocation as a multi-criteria decision-making problem. The objective is to generate a ranked list of feasible donor–recipient pairs and provide transparent decision support to the responsible clinician, who retains full responsibility for the final donor selection.
Alternative ranking is performed using the Technique for Order Preference by Similarity to Ideal Solution (TOPSIS). Criterion weights are obtained using the Analytic Hierarchy Process (AHP), which is applied exclusively to compute the preference vector (weights) of the decision criteria and validated through consistency analysis (consistency ratio). AHP is not applied directly to rank alternatives due to scalability limitations when the number of potential donors is large, which would require a quadratic number of pairwise comparisons.
The proposed framework explicitly separates criteria weighting (AHP), predictive modeling (machine learning), and final ranking (TOPSIS), thereby supporting transparency, clinical interpretability, and auditability.
The decision criteria considered in the ranking process are: HLA Match, CMV Serostatus, Donor Age Group, Gender Match, ABO Match, and Expected Survival Time. The relative importance for these criteria was defined through literature review, as shown in Table~\ref{tab:decision_criteria}. The selection of decision criteria was grounded in established clinical evidence. HLA compatibility was considered the most critical determinant of transplant outcome, with high-resolution matching at HLA-A, -B, -C, and -DRB1 remaining the gold standard and mismatches consistently associated with reduced survival \cite{dehn_selection_2019,kollman_effect_2016,jimenez_jimenez_allogeneic_2025}. Donor age was ranked as a very high-priority non-HLA criterion, as younger donors are associated with superior outcomes, with mortality risk increasing by approximately 5.5\% per 10-year age increment \cite{kollman_effect_2016,jimenez_jimenez_allogeneic_2025}. Cytomegalovirus (CMV) serostatus was classified as high priority, particularly for CMV-negative recipients, although its overall impact on survival has decreased due to improved antiviral prophylaxis \cite{kollman_effect_2016,jimenez_jimenez_allogeneic_2025,ljungman_guidelines_2019}. ABO compatibility was assigned moderate priority, mainly for operational reasons related to hemolysis risk and transfusion requirements, especially in bone marrow grafts \cite{jimenez_jimenez_allogeneic_2025}. Donor-recipient sex matching was considered a low-priority criterion and is primarily used for tie-breaking, given its association with increased GVHD risk in female-to-male transplants \cite{jimenez_jimenez_allogeneic_2025,gratwohl_gender_2016}. Finally, the predicted survival time generated by machine learning models was included as a complementary low-priority criterion to support individualized donor prioritization \cite{ratul_survival_2022,islam_rifat_children_2023}.The Predicted Survival Time has the lowest value of importance, as it is a supplementary criterion to support decision-making rather than the primary driver of donor selection. 

Because hematopoietic stem cell can have two sources (bone marrow or peripheral blood), if the source is bone marrow, the ABO compatibility criterion will have an higher importance than donor-recipient sex match, and if the source is peripheral blood, the ABO compatibility criterion will have a lower importance than donor-recipient sex match, because in this process the blood is not manipulated as in bone marrow donation, where red blood cells are removed to avoid hemolysis in case of ABO incompatibility~\cite{jimenez_jimenez_allogeneic_2025}.

\begin{table}[htbp]
\caption{Decision Criteria for Donor-Recipient Matching}
\label{tab:decision_criteria}
\centering
\small
\begin{tabularx}{\columnwidth}{c l c X}
\hline
\textbf{Rank} & \textbf{Criterion} & \textbf{Priority} \\
\hline
1 & HLA Compatibility & Critical \\

2 & Donor Age & Very High \\

3 & CMV Serostatus & High \\

4 & ABO Compatibility & Moderate \\

5 & Donor--Recipient Sex Match & Low \\

6 & Probability of success & Lowest \\
\hline
\end{tabularx}
\end{table}


Expected Survival Time (in days) is estimated using a machine learning regression model trained and validated on a publicly available dataset of pediatric unrelated-donor bone marrow transplantations, containing 187 children and adolescents between the 2000 and 2008~\cite{Sikora2010}, derived from a published pediatric unrelated-donor cohort~\cite{Kalwak2010}. The variables of this dataset are described in table \ref{tab:all_attributes} that summarizes the clinical, matching, transplantation, and outcome attributes used in this study. CMV status indicates the presence of Cytomegalovirus infection in donor or recipient. Disease indicates the specific disease of the recipient, while disease group categorizes diseases into malignant and non-malignant groups.
Gender match indicates if the transplant if froma female donor to a male receipient or any other case. HLA matching refers to the allele level donor-recipient match, while the HLA mismatch indicates if the match is superior to 8 alleles. 
CMV matching reflects donor/recipient serological status compatibility. 
CD34 and CD3 doses are reported as $\times10^6$/kg and $\times10^8$/kg, respectively, and their ratio corresponds to CD3/CD34. 
Stem cell source indicates whether cells were obtained from bone marrow or peripheral blood. Post-relapse TX indicates whether the transplant was performed after a previous relapse.
Risk group categorizes patients into two prognostic groups based on disease and disease status.
The variable \textit{Relapse} indicates whether the recipient experienced a relapse after transplantation. Survival time is measured in days from transplantation to either death or last follow-up, while survival status indicates whether the recipient was alive or deceased at last follow-up.

One of the predictive features used in this regression model is the Expected Probability of Survival, which represents a prediction of post-transplant survival within a follow-up window of three to eight years after transplantation. This survival probability is predicted using a separate regression machine learning model.
At the end of the pipeline, the system outputs an ordered ranking of donor–recipient pairs together with the estimated expected survival time. These results are presented to the clinician as decision support, enabling informed, transparent, and reproducible donor selection.

\subsection{Data Cleaning}


\begin{table}[!t]
\caption{Clinical and Transplant Attributes}
\label{tab:all_attributes}
\centering
\small
\begin{tabularx}{\columnwidth}{l X}
\hline
\textbf{Category} & \textbf{Attributes} \\
\hline
Donor &
Age, Age $<35$, ABO, CMV \\

Recipient &
Age, Age (bin), Age $<10$, Gender, Body mass, ABO, Rh, CMV, Disease, Disease group, Risk group \\

Matching &
Gender match, ABO match, CMV match, HLA match, HLA mismatch, Antigen difference, Allele difference, HLA group \\

Transplant &
Stem cell source, Post-relapse TX, CD34 dose, CD3 dose, CD3/CD34 ratio \\

Survivability Attributes &
Relapse, Survival time, Survival status \\
\hline
\end{tabularx}
\end{table}



Several data quality issues were identified and addressed prior to model development. Missing \texttt{recipient\_body\_mass} values were imputed using recipient age bins, separated by sex, since they are strongly correlated (aprox. 0.89) and can provide more accurate values than simple imputing methods. A simple linear regression model was used to impute missing \texttt{CD3\_x1e8\_per\_kg} values using \texttt{CD34\_x1e6\_per\_kg} and \texttt{recipient\_body\_mass}, also due to their strong correlation and linear nature. Analize the usefulness in outcome of some abstracted attributes like \texttt{donor\_age\_below\_35}, \texttt{recipient\_age\_below\_10}, \texttt{HLA\_mismatch}. Encode various categorical values with one-hot encoding since there is a small range of categorical values. Creation of synthetic data attributes for tissue type and donor gender to make possible HLA and gender match calculation during multi-criteria decision making. Check and handle bias and minority classes in outcome features using stratification and oversampling. Handle highly correlated features by removing the less performing ones, simplifying the generalization with few data rows.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\columnwidth]{figures/cd3_cd34_body_mass_corr.png}
    \caption{Correlation between CD3$^{+}$, CD34$^{+}$ and recipient body mass}
    \label{fig:cd3_cd34_body_mass_correlation}
\end{figure}

A new \texttt{missing\_(feature)} attribute was created for each value equal to "?", particularly in \texttt{(donor-recipient)\_CMV}, \texttt{ABO\_match}, \texttt{(donor-recipient)\_ABO} and \texttt{CMV\_status}.

The dataset provides a lot of data to better understand the match and transplant variables influence in survivability. It will be useful for finding correlations and importance of each attribute during the allocation fase, but will need to be simplified in order to help the model predict and generalize better with the small sample size.

\subsection{Data Exploration}

One of the first steps in data exploration is to analyze if the target data is biased in any way. This can be done by checking the proportions of the \texttt{survival\_status} attribute. In this dataset, 54\% of people are alive, while 45\% are deceased, which means that the target is slightly unbalanced. Looking at the data, a possible important factor is the correlation between the ages of the recipient and the donor. Fig.\ref{fig:age_correlation} shows the correlation between the pairs:

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\columnwidth]{figures/age_correlation.png}
    \caption{Age correlation of donor-recipient pairs}
    \label{fig:age_correlation}
\end{figure}

This graph shows that a lot of transplants are made with donor-recipient pairs where the donor is between the ages of 25--45 years old and the recipient between 5--15 years old. Another thing to explore could be the correlation between the age gap of the pair. However, analysis suggests that the donor-recipient age gap doesn't have a strong enough correlation with either survival time or survival status of the recipient. Another attribute worth exploring is how blood type compatibility affects survival. Exploratory analysis showed that, while in case there is a blood type match the rate of survival is very close to 50\%, in case of a blood type mismatch the rate of survival drops to close to 40\%, showing a possible small correlation between these attributes. Gender matching can also be an important factor to consider in compatibility; however, analysis shows that gender matching alone isn't sufficient to form a correlation.

In addition to this, it can also be noted a very big imbalance in the target \texttt{relapse}, where 85\% of samples are negative.

\subsection{Feature Engineering}
By default, the dataset already comes with various abstracted features. A small number were added or altered. Some of the new engineered features include the addition of the \texttt{age\_gap} feature, which is calculated using the absolute difference between the recipient-donor pair; the binning of the \texttt{donor\_age} and \texttt{recipient\_age} features; and the \texttt{total\_mismatches} feature, which is calculated using the total number of mismatched allels and antigens between donor and recipient.

Careful selection was important in order to reduce the high dimensionality of the data and help the models generalize better as well as reduce overfitting.
\subsection{Oversampling}
Regarding oversampling, two types were tested in this project:
\subsubsection{Synthetic Minority Over-sampling Technique (SMOTE)}
SMOTE is used in unbalanced datasets to create more samples of the minority class using a k-nearest neighbours algorithm \cite{Chawla_2002}. This way, new samples are not equal to existing ones, but slightly different variations of existing minority class samples. In this case, slight variations of SMOTE were used such as SMOTE-NC (for nominal and countinous data) and Adaptive Synthetic Sampling (ADASYN).

\subsubsection{Generative Adversarial Networks (GANs)}
GANs utilize neural networks to learn and generate synthetic data, which makes them a more robust and powerful alternative to other techniques \cite{gans}.


\section{System Architecture}
For this project, the system architecture is composed of two modules that work together to achieve the desired functionality. These two modules are:
\begin{itemize}
    \item A prediction system with a api that exposes endpoints for predicting survival classification, survival time regression and relapse with BentoML \cite{Yang2024BentoML}. The prediction models with the best scores were trainned and imported from MLflow \cite{Zaharia2018MLflow}.
    \item A simple flask api that serves a web application for user interaction and calls the BentoML prediction system api for predictions.
\end{itemize}
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\columnwidth]{figures/arquitecture_diagram.png}
    \caption{Architecture Diagram}
    \label{fig:architecture_diagram}
\end{figure}

\section{Experiments}
Approximately 150 experiments with different models and model configurations were made. To facilitate this, MLflow and Hydra were used for tracking and result reproducibility across model configurations. \cite{Yadan2019Hydra}


\subsection{Survival Classification}
For survival classification, several model families were tested. All models were tested in three different configurations: default parameters, tuned and tuned with SMOTE. Every tuned model was also tested with different feature engineering steps. Additionally, the best models were also tested using GANs with different combinations of epochs and synthetic sample sizes. Different number of training cross validation folds and train-test splits were also considered. Finally, different methods of hyperparameter optimization (Grid Search, Random Search and Optuna) were explored and compared. \cite{optuna_2019} 

As metrics, the F1-score on the test set was the main metric used for final model comparison but several other metrics were also used such as the accuracy, precision, recall and cross-validation F1-score of the train set.

Linear classification models, including the Logistic Regression were evaluated as a baseline. Tree ensemble models like the Random Forest (RF) and the Extra Trees (ET), and gradient boosting models like the XGBoost (XGB) and the LightGBM (LGBM) were also tested. Alternating Decision Trees (ADTrees) and Support Vector Machines (SVMs) were also considered.

\subsection{Survival Time Regression}

To predict survival time, tests were performed on largely the same model families as the classification task. For the linear models family, ridge regression and elastic-net were tested. All models were tested with and without the addition of the classification variable predicted by the best classification model, tuned and untuned. Additionally, the classification variable was tested being predicted as a binary variable or as a probability. Metrics such as the Root Mean Squared Error (RMSE), Mean Average Error (MAE) and the coefficient of determination ($R^2$), were saved for both train and test sets and used to compare the regression models. A baseline RMSE value was also set (RMSE = 913), which represents a simple model in which every patient is given the average survival time of the dataset.

\subsection{Relapse Classification}

Various models were tested: Logistic Regression, k-Nearest Neighbors, Stochastic Gradient Descent, Random Forests and more. Model performance was primarily assessed through confusion matrices, ROC curves and precision–recall curves. Resampling techniques were applied to address class imbalance. In addition, the class weight parameter was set to balanced (when resampling was not used), and recall was selected as the main scoring metric during model optimization. These strategies improved significantly positive classification performance across all models. Feature selection was preferred over dimensionality reduction, because in the medical field, understanding the contribution of each feature to the predicted outcome is critical.

Despite the best efforts, achieving favorable results with a such limited dataset proved to be quite challenging. It was required to implement multiple iterative adjustments while carefully avoiding extensive hyperparameter tuning or frequent evaluation on the test data to prevent overfitting.

\section{Results and Discussion}
The section evaluates the performance of different ML models for the prediction of both a classification target and a regression target and analyzes the impact of feature engineering, hyperparameter tuning and data augmentation techniques.

\subsection{Survival Classification}

Out of all the experiments, the tuned XGBoost with GAN-augmented data obtained the best result, with an F1-score of 0.68 on the test set, a precision of 0.58, a recall of 0.63 and an accuracy of 0.64. However, the model that, on average, achieved the best results was the Logistic Regression, having the base untuned model ranked as the best model not utilizing GANs.

Bayesian hyperparameter tuning using Optuna did not consistently outperform grid search or random search in test performance. However, it reached very similar results significantly faster and sometimes even outperforming other methods.

Further, it was observed that SMOTE oversampling for the minority class did not significantly help in predicting the patient survival, having the models with SMOTE achieved an F1-score on the test set of 0.45, and 0.44 without, with precision and recall being very similar. On the other hand, GAN oversampling improved significantly the results, reaching an average F1-score on the test set of 0.50, against 0.44 without. 

On average, the tuned models without oversampling had better overall performance than the untuned models, however, it is important to note that some untuned models performed significantly better than their tuned conter-parts, even when confining their grid search, as can be seen in Fig.\ref{fig:tune_vs_untune}. It was observed that simpler models like Logistic Regression and SVM often had better results than more complex models. 

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\columnwidth]{figures/tune_vs_untune.png}
    \caption{Performance of tuned (no oversampling) vs. untuned models}
    \label{fig:tune_vs_untune}
\end{figure}

This is possibly due to the small dataset size which causes many of the more complex models, even on default parameters, to overfit the training data, causing poor performance on the test set. Due to this, simpler models are often able to create a better generalization.

GAN-augmentation had a significant impact in model performance for tree models, while negatively affecting linear models. Gradient boosting models also were positively affected. Several GAN configurations were attempted and it was observed that the one that produced the best results overall results was a sample size of 10 synthetic entries for class 0, 20 synthetic entries for class 1 and the the number of epochs set to 300.

Another observation was made when comparing the cross-validation F1-Score on the train set with the test set. As can be seen in the sample of parallel coordinates plot in Fig.\ref{fig:train_vs_test}, 12 random experiments were chosen, and compared. It was observed that experiments that scored a high F1-score on cross-validation with the train set performed consistently worse on the test set than those that scored a lower value.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\columnwidth]{figures/train_vs_test.png}
    \caption{Comparison between train and test set performance across experiments}
    \label{fig:train_vs_test}
\end{figure}
\FloatBarrier

These observations are consistent with the previous hypothesis. With more data, tree models don't overfit the training set as much, and get better results. However, it is important to note that data quality also plays a big role, because simply generating more data using GANs doesn't always yield better results. With little data, GANs can also overfit the train set and generate synthetic data that is too close to the real set which only adds noise. On the other hand, reducing the number of epochs too much can also cause them to not learn enough about the data. 

Some additional experiments were made on the best-performing models comparing different values for number of cross validation folds and train/test split ratios. It was observed that training the model with 5 folds and a test set size of 15\% of the total dataset yielded better results.

\subsection{Survival Time Regression}

As can be seen in Fig. \ref{fig:use_clf}, using classification prediction as a feature to predict regression considerably improved model performance.
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\columnwidth]{figures/classification_influence.png}
    \caption{Use of classification as feature for regression}
    \label{fig:use_clf}
\end{figure}

Using the red line to indicate the baseline level, the RMSE of the models not using classification were all observed to be above that level. However, by adding the survival status as a feature the RMSE was cut almost in half.
Moreover, predicting the survivability as a probability instead of a binary feature produced mixed results across models and configurations, with tree and linear models performing particularly bad, however, gradient boosting models like LightGBM and XGBoost had better results than the same model with a binary classification feature.

As with classification, different numbers of cross-validation folds were tested and 5 folds was observed to produce the best results.

In the end, the regression model that preformed best was a tuned Extra Trees Regressor model using survival status as a probability.


\subsection{Relapse Classification}

Finally, for relapse prediction, due to the big similarity of the dataset to the previous classification model, only the models that performed best were tested. In this case, the XGBoost with GAN augmentation was also the best model. However, due to the limited dataset size, and significant class inbalance, prediction results were not satisfactory. Even utilizing GAN augmentation, the best model achieved a macro F1-Score of 0.47.

\subsection{SHAP Analysis}
To improve model explainability, a general SHapley Additive exPlanation (SHAP) analysis was performed and plotted for the best-performing classification and regression model~\cite{Lundberg2017SHAP}.
Each dot represents a single data point of the respective feature.
The x-axis represents the SHAP value, which is a measure of the impact of each feature on the model's prediction (a negative shap means the model is more likely to predict the patient's survival, while a positive value means the opposite). The color of each dot represents the value of the feature for that data point.
A red dot represents a high value and a blue dot represents a low value.
For example, in the feature \texttt{age\_gap}, a red dot represents a high age gap value and a blue dot represents a low age gap value.
The ordering of the dots along the y-axis does not affect interpretability and is used only to improve visualization.
It should be noted that SHAP analysis was performed strictly post hoc and was not used to guide feature engineering decisions.
Fig.\ref{fig:clf_shap} shows a beeswarm plot of the most important features for the classification model.
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\columnwidth]{figures/clf_shap.png}
    \caption{SHAP Analysis for classification model}
    \label{fig:clf_shap}
\end{figure}

Fig.\ref{fig:reg_shap} shows a beeswarm plot of the top 3 features for the regression model.
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\columnwidth]{figures/reg_shap.png}
    \caption{SHAP Analysis for regression model}
    \label{fig:reg_shap}
\end{figure}

Some features are very strong and clean indicators of the model's prediction. For example, the feature \texttt{risk\_group\_low} being positive is a big indicator that the model will predict the patients survival. To add to this, it can be observed that most binary features form separated clusters, indicating a consistent directional impact on the model's prediction depending on feature value. However, that's not always the case, as can be seen in the feature \texttt{ABO\_match\_mismatched} or \texttt{donor\_CMV\_present}. It can also be observed that the engineered features \texttt{age\_gap} and \texttt{recipient\_age\_bin} had a strong impact on the model's prediction. 

Furthermore, it can clearly be seen that the survival status of the patient is a strong indicator of the model's prediction for the regression model.

\section{Conclusion}
\subsection{Main findings}
The results indicate that simpler models, particularly logistic regression, exhibit strong generalization performance in small datasets, while more complex models are more prone to overfitting. Although GAN-based data augmentation improved the performance of tree-based and gradient boosting models, its performance was highly dependent on data quality. Incorporating survival classification outputs as features for survival time regression significantly reduced prediction error. Furthermore, the survival time prediction succeeded in yielding significantly better results than baseline levels.

Beyond predictive performance, this work demonstrates the feasibility of integrating ML models into a structured multi-criteria decision-support pipeline for donor allocation. By explicitly separating outcome prediction (ML), preference elicitation (AHP), and alternative ranking (TOPSIS), the proposed framework supports transparent, reproducible, and auditable clinical decision-making. The resulting ranked donor–recipient lists provide clinicians with interpretable recommendations that combine data-driven predictions with established clinical priorities, thereby facilitating informed and accountable allocation decisions.


\subsection{Limitations}
\subsubsection{Small Dataset}
The biggest limitation of this project was the limited dataset size. A size of around 180 total samples, means there are not enough samples for the model to create a good generalization and the test is too small to have a clear idea of how the model would preform with new data. 

\subsubsection{Class imbalance}
Additionally the dataset shows a small class imbalance for the \texttt{survival\_status} variable which was able to be remedied utilizing oversampling techniques. However, there is a much more significant imbalance for the variable \texttt{relapse}.

\subsubsection{Decision-Level Validation}
While the predictive models were evaluated quantitatively, the decision-support component has not yet been prospectively validated in real clinical workflows. Future work should include clinician-in-the-loop evaluations to assess usability, interpretability, and real-world impact on donor selection decisions.


\section*{Acknowledgment}
The authors thank the lecturers of the Master in Artificial Intelligence Engineering (MEIA) at the Porto School of Engineering (ISEP) for the guidance and support provided throughout the development of this project.

\bibliographystyle{IEEEtran}
\bibliography{references}

\clearpage
\onecolumn
\appendices
\section{Additional Survival Classification Results}
\begin{table}[htbp]
    \caption{Examples of Survival Classification Experiment Results}
    \label{tab:clf_appendix}
    \centering
    \begin{tabular}{l l l l c c c c c c}
        \toprule
        \textbf{Model}                          &
        \textbf{Tuning}                         &
        \textbf{SMOTE}                          &
        \textbf{GAN}                            &
        \multicolumn{2}{c}{\textbf{GAN Config}} &
        \multicolumn{4}{c}{\textbf{Metrics}}                                                                \\
        \cmidrule(lr){5-6} \cmidrule(lr){7-10}
                                                &     &     &     &
        \textbf{Epochs}                         &
        \textbf{Samples}                        &
        \textbf{F1$_{test}$}                   &
        \textbf{F1$_{cv}$}                      &
        \textbf{Precision}                      &
        \textbf{Recall}                                                                                     \\
        \midrule
        Logistic Regression & No  & No  & No  & --  & --    & 0.55 & 0.53 & 0.50 & 0.53 \\
        Logistic Regression & Yes & No  & No  & --  & --    & 0.50 & 0.54 & 0.44 & 0.30 \\
        Logistic Regression & Yes & Yes & No  & --  & --    & 0.51 & 0.57 & 0.46 & 0.46 \\
        Logistic Regression & Yes & Yes & No  & 300 & 10/20 & 0.58 & 0.53 & 0.53 & 0.53 \\
        \addlinespace

        Random Forest & No  & No  & No  & --  & --    & 0.44 & 0.61 & 0.38 & 0.30 \\
        Random Forest & Yes & No  & No  & --  & --    & 0.37 & 0.65 & 0.27 & 0.23 \\
        Random Forest & Yes & Yes & No  & --  & --    & 0.51 & 0.63 & 0.46 & 0.46 \\
        Random Forest & Yes & Yes & No  & 300 & 10/20 & 0.62 & 0.67 & 0.65 & 0.59 \\
        \addlinespace

        XGBoost & No  & No  & No  & --  & --    & 0.41 & 0.55 & 0.37 & 0.46 \\
        XGBoost & Yes & No  & No  & --  & --    & 0.48 & 0.62 & 0.41 & 0.53 \\
        XGBoost & Yes & Yes & No  & --  & --    & 0.48 & 0.63 & 0.43 & 0.53 \\
        XGBoost & Yes & Yes & No  & 300 & 10/20 & 0.68 & 0.57 & 0.66 & 0.61 \\
        XGBoost & Yes & Yes & No  & 200 & 10/20 & 0.51 & 0.59 & 0.48 & 0.55 \\
        \addlinespace

        LightGBM & No  & No  & No  & --  & --    & 0.44 & 0.55 & 0.40 & 0.46 \\
        LightGBM & Yes & No  & No  & --  & --    & 0.41 & 0.57 & 0.35 & 0.38 \\
        LightGBM & Yes & Yes & No  & --  & --    & 0.44 & 0.59 & 0.40 & 0.46 \\
        \addlinespace

        Extra Trees & No  & No  & No  & --  & --    & 0.38 & 0.59 & 0.33 & 0.38 \\
        Extra Trees & Yes & No  & No  & --  & --    & 0.38 & 0.63 & 0.33 & 0.38 \\
        Extra Trees & Yes & Yes & No  & --  & --    & 0.41 & 0.62 & 0.35 & 0.38 \\

        \bottomrule
    \end{tabular}
\end{table}

\end{document}